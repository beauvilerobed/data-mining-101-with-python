{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Insight Using Naive Bayes\n",
    "\n",
    "\n",
    "Text-based datasets contain a lot of information, whether they are books, historical documents, social media, e-mail, or any of the other ways we communicate via writing. Extracting features from text-based datasets and using them for classification is a difficult problem. There are, however, some common patterns for text mining. We look at disambiguating terms in social media using the Naive Bayes algorithm, which is a powerful and surprisingly simple algorithm. Naive Bayes takes a few shortcuts to properly compute the probabilities for classification, hence the term naive in the name. It can also be extended to other types of datasets quite easily and doesn't rely on numerical features. The model is a baseline for text mining studies, as the process can work reasonably well for a variety of datasets.\n",
    "\n",
    "We will cover the following topics in this chapter:\n",
    "- Downloading data from social network APIs\n",
    "- Transformers for text\n",
    "- Naive Bayes classifier\n",
    "- Using JSON for saving and loading datasets\n",
    "- The NLTK library for extracting features from text\n",
    "- The F-measure for evaluation\n",
    "\n",
    "## Disambiguation\n",
    "\n",
    "Text is often called an **unstructured** format. There is a lot of information there, but it is just there; no headings, no required format, loose syntax and other problems prohibit the easy extraction of information from text. The data is also highly connected, with lots of mentions and cross-references—just not in a format that allows us to easily extract it!\n",
    "\n",
    "We can compare the information stored in a book with that stored in a large database to see the difference. In the book, there are characters, themes, places, and lots of information. However, the book needs to be read and, more importantly, interpreted to gain this information. The database sits on your server with column names and data types. All the information is there and the level of interpretation needed is quite low. Information about the data, such as its type or meaning is called **metadata**, and text lacks it. A book also contains some metadata in the form of a table of contents and index but the degree is significantly lower than that of a database. \n",
    "\n",
    "One of the problems is the term **disambiguation**. When a person uses the word bank, is this a financial message or an environmental message (such as river bank)? This type of disambiguation is quite easy in many circumstances for humans (although there are still troubles), but much harder for computers to do.\n",
    "\n",
    "Here, we will look at disambiguating the use of the term Python on Twitter's stream. A message on Twitter is called a tweet and is limited to 140 characters. This means there is little room for context. There isn't much metadata available although hashtags are often used to denote the topic of the tweet.\n",
    "\n",
    "When people talk about Python, they could be talking about the following things:\n",
    "- The programming language Python\n",
    "- Monty Python, the classic comedy group\n",
    "- The snake Python\n",
    "- A make of shoe called Python\n",
    "\n",
    "There can be many other things called Python. The aim of our experiment is to take a tweet mentioning Python and determine whether it is talking about the programming language, based only on the content of the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data from a social network\n",
    "\n",
    "We are going to download a corpus of data from Twitter and use it to sort out spam from useful content. Twitter provides a robust API for collecting information from its servers and this API is free for small-scale usage. It is, however, subject to some conditions that you'll need to be aware of if you start using Twitter's data in a commercial setting.\n",
    "\n",
    "First, you'll need to sign up for a Twitter account (which is free). Go to http://twitter.com and register an account if you do not already have one.\n",
    "\n",
    "Next, you'll need to ensure that you only make a certain number of requests per minute. This limit is currently 180 requests per hour. It can be tricky ensuring that you don't breach this limit, so it is highly recommended that you use a library to talk to Twitter's API.\n",
    "\n",
    "You will need a key to access Twitter's data. Go to http://twitter.com and sign in to your account.\n",
    "\n",
    "When you are logged in, go to https://apps.twitter.com/ and click on Create New App.\n",
    "\n",
    "Create a name and description for your app, along with a website address. If you don't have a website to use, insert a placeholder. Leave the Callback URL field blank for this app—we won't need it. Agree to the terms of use (if you do) and click on Create your Twitter application.\n",
    "\n",
    "Keep the resulting website open—you'll need the access keys that are on this page. Next, we need a library to talk to Twitter. There are many options; the one I like is simply called twitter, and is the official Twitter Python library.\n",
    "\n",
    "Note: You can install twitter using pip3 install twitter if you are using pip to install your packages. If you are using another system,check the documentation at https://github.com/sixohsix/ twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import twitter\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# consumer_key = \"<Your Consumer Key Here>\"\n",
    "# consumer_secret = \"<Your Consumer Secret Here>\"\n",
    "# access_token = \"<Your Access Token Here>\"\n",
    "# access_token_secret = \"<Your Access Token Secret Here>\"\n",
    "# authorization = twitter.OAuth(access_token, access_token_secret,\n",
    "# consumer_key, consumer_secret)\n",
    "\n",
    "# output_filename = os.path.join(os.path.expanduser(\"~\"),\n",
    "#  \"Data\", \"twitter\", \"python_tweets.json\")\n",
    "\n",
    "\n",
    "# t = twitter.Twitter(auth=authorization)\n",
    "\n",
    "# with open(output_filename, 'a') as output_file:\n",
    "#     search_results = t.search.tweets(q=\"python\", count=100)['statuses']\n",
    "#     for tweet in search_results:\n",
    "#         if 'text' in tweet:\n",
    "#             output_file.write(json.dumps(tweet))\n",
    "#             output_file.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding loop, we also perform a check to see whether there is text in the tweet or not. Not all of the objects returned by twitter will be actual tweets (some will be actions to delete tweets and others). The key difference is the inclusion of text as a key, which we test for.\n",
    "\n",
    "Running this for a few minutes will result in 100 tweets being added to the\n",
    "output file.\n",
    "\n",
    "## Loading and classifying the dataset\n",
    "\n",
    "After we have collected a set of tweets (our dataset), we need labels to perform classification. The dataset we have stored is nearly in a JSON format. JSON is a format for data that doesn't impose much structure and is directly readable in JavaScript (hence the name, JavaScript Object Notation). JSON defines basic objects such as numbers, strings, lists and dictionaries, making it a good format for storing datasets if they contain data that isn't numerical. If your dataset is fully numerical, you would save space and time using a matrix-based format like in NumPy.\n",
    "\n",
    "To parse it, we can use the json library but we will have to first split the file by newlines to get the actual tweet objects themselves.\n",
    "\n",
    "## Loading data without the twitterAPI\n",
    "We do not need to used the twitterAPI or anything of the like. There is a saved .txt file that has 100 tweets that we will use. If you wish to use the twitterAPI feel free to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'data/social-media-data/'\n",
    "TWITTER = DATA + 'posts.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 99 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets_set = {}\n",
    "tweets_list = []\n",
    "with open(TWITTER, \"r\") as file:\n",
    "    content = file.read().split('\\n\\n')\n",
    "    for i, line in enumerate(content):\n",
    "        try: \n",
    "            user, tweet = line.split('\\n')\n",
    "            tweets_set[i] = {'user': user,\n",
    "                            'text': tweet}\n",
    "            tweets_list.append([user, tweet])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(f\"Loaded {len(tweets_list)} tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now interested in classifying whether an item is relevant to us or not (in this case, relevant means refers to the programming language Python). We will use the IPython Notebook's ability to embed HTML and talk between JavaScript and Python to create a viewer of tweets to allow us to easily and quickly classify the tweets as spam or not.\n",
    "\n",
    "The code will present a new tweet to the user (you) and ask for a label: is it relevant\n",
    "or not? It will then store the input and present the next tweet to be labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sample = tweets_set\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instructions = f\"\"\"\n",
    "# Instructions: Click in textbox. Enter a 1 if the tweet is relevant, enter 2 otherwise.\n",
    "# \"\"\"\n",
    "# print(instructions)\n",
    "# while len(labels) <= len(tweets_list):\n",
    "#     try:\n",
    "#         tweet_text = tweet_sample[len(labels)]['text']\n",
    "#     except:\n",
    "#         print(f'key value {len(labels)} DNE')\n",
    "#         labels.append(-1)\n",
    "\n",
    "#     tweet = f\"\"\"\n",
    "# Tweet: {tweet_sample[len(labels)]['text']}\n",
    "#     \"\"\"\n",
    "#     print(tweet)\n",
    "#     a = input()\n",
    "#     try:\n",
    "#         if a == 'end':\n",
    "#             break\n",
    "#         val = int(a)\n",
    "#         if val in [1,2]:\n",
    "#             labels.append(int(a))\n",
    "#         else:\n",
    "#             print('invalid input: must be 0 or 1')\n",
    "#     except:\n",
    "#         print('invalid input: must be 0 or 1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a label with -1 is n/a\n",
    "with open(DATA+'labels.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "    label_vals = content.split('\\n')\n",
    "    for val in label_vals:\n",
    "        labels.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = min(len(tweet_sample), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a replicable dataset from Twitter\n",
    "\n",
    "In data mining, there are lots of variables. These aren't just in the data mining\n",
    "algorithms—they also appear in the data collection, environment, and many other\n",
    "factors. Being able to replicate your results is important as it enables you to verify\n",
    "or improve upon your results.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "Getting 80 percent accuracy on one dataset with algorithm X, and\n",
    "90 percent accuracy on another dataset with algorithm Y doesn't\n",
    "mean that Y is better. We need to be able to test on the same\n",
    "dataset in the same conditions to be able to properly compare.\n",
    "\n",
    "On running the preceding code, you will get a different dataset to the one I created\n",
    "and used. The main reasons are that Twitter will return different search results\n",
    "for you than me based on the time you performed the search. Even after that,\n",
    "your labeling of tweets might be different from what I do. While there are obvious\n",
    "examples where a given tweet relates to the python programming language, there will\n",
    "always be gray areas where the labeling isn't obvious. One tough gray area I ran into\n",
    "was tweets in non-English languages that I couldn't read. In this specific instance,\n",
    "there are options in Twitter's API for setting the language, but even these aren't\n",
    "going to be perfect.\n",
    "\n",
    "Due to these factors, it is difficult to replicate experiments on databases that are\n",
    "extracted from social media, and Twitter is no exception. Twitter explicitly disallows\n",
    "sharing datasets directly.\n",
    "\n",
    "One solution to this is to share tweet IDs only, which you can share freely. In this\n",
    "section, we will first create a tweet ID dataset that we can freely share. Then, we will\n",
    "see how to download the original tweets from this file to recreate the original dataset.\n",
    "\n",
    "First, we save the replicable dataset of tweet IDs. Creating another new IPython\n",
    "Notebook, first set up the filenames. This is done in the same way we did labeling\n",
    "but there is a new filename where we can store the replicable dataset. The code is\n",
    "as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: RT @seira_923: [Python] Help with a tricky loop issue, how do you use continue to  http://t.co/H54k0nWDiN http://t.co/FydAl78nvH\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @otoka_380: Python/Flask app using apache/fastcgi producing 500 Error http://t.co/sn4d0S5aHD\n",
      "label: 1 \n",
      "\n",
      "tweet: ?? 이건 visual studio 에러인가 python 컴파일러로 돌리면 에러 안나고 잘 돌아가는데 vs 디버거로 돌리면 에러를 뱉어내는군\n",
      "label: 1 \n",
      "\n",
      "tweet: Första klassens \"tomte\" #moron http://t.co/yMt1PZU1Cp\n",
      "label: 2 \n",
      "\n",
      "tweet: Python #private #class variables that aren't class variables: When trying to access… http://t.co/4yIhHsIizx\n",
      "label: 1 \n",
      "\n",
      "tweet: “Pythonディープラーニングライブラリのツートップ「Pylearn2」「Caffe」とは～PyData Tokyo Meetup #1イベントレポート （1/3）：CodeZine” http://t.co/M5qsyZZTnD\n",
      "label: 1 \n",
      "\n",
      "tweet: Four Beautiful Python, R, MATLAB, and Mathematica plots with LaTeX http://t.co/8krYerBJfB via @rbloggers\n",
      "label: 1 \n",
      "\n",
      "tweet: @0243Kyon http://t.co/mSyeNVcahe\n",
      "label: 2 \n",
      "\n",
      "tweet: @io_python うわぁ...\n",
      "label: 1 \n",
      "\n",
      "tweet: #Freelancer Python Restless Example by homejinni http://t.co/QRDLJxlsIM #computer via @BlueWaterMarket\n",
      "label: 1 \n",
      "\n",
      "tweet: #Freelancer Python Crawler/Indexer/Spider/Bot by meetire http://t.co/CbzQTdVXdi #computer via @BlueWaterMarket\n",
      "label: 1 \n",
      "\n",
      "tweet: @0243Kyon 泣けよ(ゲス顔)\n",
      "label: 2 \n",
      "\n",
      "tweet: #Freelancer #seo Python Restless Example by homejinni http://t.co/RmZQVvMlz2 @CashBoards\n",
      "label: 1 \n",
      "\n",
      "tweet: #Freelancer #seo Python Crawler/Indexer/Spider/Bot by meetire http://t.co/GWf3vHkZ30 @CashBoards\n",
      "label: 1 \n",
      "\n",
      "tweet: SchemePy 1.1.01: R5RS scheme interpreter, supporting hygenic macros and full call/cc http://t.co/cN4bfcStmm\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @shiftkey: current status: installing the other version of python\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @shiftkey: current status: installing python\n",
      "label: 1 \n",
      "\n",
      "tweet: #python floraconcierge-client 0.6.7: FloraExpress API python client library. http://t.co/0TfRRqsOR8 http://t.co/Ew6FJoY9Hx\n",
      "label: 1 \n",
      "\n",
      "tweet: #python printNest21 1.4.0: A simple printer of nested lists http://t.co/1OPTOogruI\n",
      "label: 1 \n",
      "\n",
      "tweet: #python pyupp 0.1: Read and write unity player preferences data. http://t.co/SF7gUilR8x\n",
      "label: 1 \n",
      "\n",
      "tweet: #python musa 3.3.13: Module for music tagging and library management http://t.co/Wg2qcbMeCS\n",
      "label: 1 \n",
      "\n",
      "tweet: Lady - Python [Hiphop?] https://t.co/nekBNpmHvL\n",
      "label: 2 \n",
      "\n",
      "tweet: https://t.co/WKdTIueR9S\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @shiftkey: current status: installing the other version of python\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @shiftkey: current status: installing python\n",
      "label: 1 \n",
      "\n",
      "tweet: “http://t.co/oAqSNLIRXP： Python言語によるプログラミングイントロダクション: 世界標準MIT教科書: 久保 幹雄, John V. Guttag, 麻生 敏正, 木村 泰紀, 小林 和博, 関口 良行…” http://t.co/qAmAQ0skir\n",
      "label: 2 \n",
      "\n",
      "tweet: Top hourly 'python' htags [bm500.., #python, #cgyvsvan, #rdsch, #3dmu] 377 tweets http://t.co/l5IY5gFCyK http://t.co/CEOidrDhmv\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @yuhiro_274: Linking python as backed when using Django + Bower + Grunt http://t.co/MDMfhkRyKS\n",
      "label: 2 \n",
      "\n",
      "tweet: @Michael_Louis_ Python Accessories\n",
      "label: 2 \n",
      "\n",
      "invalid key: 29 \n",
      "\n",
      "tweet: Black Hat Python: Python Programming for Hackers and Pentesters http://t.co/qBknn5EDOX 3325 http://t.co/JpLvvwjPOz\n",
      "label: 1 \n",
      "\n",
      "invalid key: 31 \n",
      "\n",
      "tweet: perl oneliner, python oneliner 등등의 언어별 oneliner중에서 가장 변태는 lisp 계열 아닐까?\n",
      "label: 2 \n",
      "\n",
      "invalid key: 33 \n",
      "\n",
      "tweet: floraconcierge-client 0.6.7: FloraExpress API python client library. http://t.co/dXyHxnjqcK http://t.co/wo4TTGYIHx\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @ElBaulDeKubrick: Still Flying, un tributo a los Monty Python http://t.co/PYb9h5Gssk ¿Alguien los ha olvidado? http://t.co/TooNHtSiMm\n",
      "label: 2 \n",
      "\n",
      "tweet: Four Beautiful Python, R, MATLAB, and Mathematica plots with LaTeX http://t.co/Dgpmvoocdn #rstats\n",
      "label: 1 \n",
      "\n",
      "tweet: @Bergg69 @Canada yep. Like Monty Python 'Dennis Moore' sketch. Rob the poor to give to the rich.\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @urara_645: Keep This Python Cheat Sheet on Hand When Learning to Code http://t.co/R72YIj24j4 http://t.co/FtEYHLwj6H\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @mura_cin: Pythonで変数名をつけるときには予約語だけでなく組み込み関数との衝突も気を付けましょう on @Qiita http://t.co/1n5c7ut7Dl\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @seira_923: [Python] Is this if-statement correct (conceptually)? http://t.co/dYy9pXaSkj http://t.co/p42JgUVIEV\n",
      "label: 1 \n",
      "\n",
      "tweet: Is there any reason I should witch to python 3 http://t.co/t17y7JI92b http://t.co/A0oxjbpOn2\n",
      "label: 1 \n",
      "\n",
      "tweet: printNest21 1.4.0: A simple printer of nested lists http://t.co/h5iLQ3zTil\n",
      "label: 1 \n",
      "\n",
      "tweet: @shiftkey a python install for you! And a python install for you. Everyone gets a python install!\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @seino_988: Making GIFs from Video Files with Python http://t.co/xOelfi2SKU\n",
      "label: 1 \n",
      "\n",
      "tweet: @python_octopus お疲れさまでした！これで心置きなくですか…？\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @kuroneko1988: ごめんなさい．ごめんなさい．やっつけです/Sinatra風マイクロフレームワークで始めるPython http://t.co/0rCghxCNGh @SlideShareさんから\n",
      "label: 2 \n",
      "\n",
      "tweet: https://t.co/basmBzXZNb\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @seira_923: Python: Is it a good starting point? http://t.co/mvnIxwRn8V http://t.co/vTVQPN16XF\n",
      "label: 1 \n",
      "\n",
      "tweet: @halulan 蟻です！！\n",
      "label: 2 \n",
      "\n",
      "tweet: Fuck work.\n",
      "label: 2 \n",
      "\n",
      "invalid key: 51 \n",
      "\n",
      "tweet: Vince Camuto Women's VC/5022RGBN Leather Rosegold-Tone Date Function Brown Python Strap Watch   http://t.co/imePT9i3gx\n",
      "label: 2 \n",
      "\n",
      "tweet: python-rpy2 2.5.4-1 x86_64 http://t.co/oawb8APara #Archlinux\n",
      "label: 2 \n",
      "\n",
      "tweet: python-rpy2 2.5.4-1 i686 http://t.co/TnMRb22DI2 #Archlinux\n",
      "label: 1 \n",
      "\n",
      "tweet: current status: installing the other version of python\n",
      "label: 1 \n",
      "\n",
      "tweet: current status: installing python\n",
      "label: 1 \n",
      "\n",
      "tweet: Using BOTH error bars and upper/lower limits in python http://t.co/X5FyAWHikJ\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @NYDailyNews: A 15-foot Burmese python was found at a Florida real estate office. http://t.co/ry0yXBZ6Ek http://t.co/1CQVQuZVjj\n",
      "label: 1 \n",
      "\n",
      "tweet: @kazunaduck おつありですうぇひひひひ！！\n",
      "label: 2 \n",
      "\n",
      "tweet: Woman Finds Python In Secondhand S-s-s-s-sofa http://t.co/hvWepmNbD6 http://t.co/r2g2xHF0kE\n",
      "label: 2 \n",
      "\n",
      "tweet: @python_octopus お疲れさまですうぇへへへへ！！\n",
      "label: 2 \n",
      "\n",
      "tweet: @Escalator_Rider 『おつありさまっす』\n",
      "label: 2 \n",
      "\n",
      "tweet: @kobudashiOdashi あっっっっっっっっっっ！！！！！！！！\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @Python_Quest: How to add assumptions in limit in Sympy? http://t.co/um3d45PzDu http://t.co/t3TXOZrjLV #Python via @dv_geek\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @Python_Quest: Dealing with list.index(x) error in Python 3 http://t.co/0jp5moJqwh http://t.co/Ntbf0XWdt2 #Python via @dv_geek\n",
      "label: 1 \n",
      "\n",
      "tweet: @python_octopus 『おつかれさまっす』\n",
      "label: 2 \n",
      "\n",
      "tweet: @mechashiorina おつありでございます！！\n",
      "label: 2 \n",
      "\n",
      "tweet: Michael Kors Hamilton Python Embossed Leather Large Brown Mocha Tote Purse Bag - Full read by eBay: Price 339.0 USD… http://t.co/IkkhhgJrrn\n",
      "label: 2 \n",
      "\n",
      "tweet: Monty Python - Always Look on the Bright Side of …: http://t.co/xYHUiKxp4K\n",
      "label: 2 \n",
      "\n",
      "tweet: @python_octopus おっっっっっっっっっっっっっっっっっっっっっｔ\n",
      "label: 2 \n",
      "\n",
      "tweet: @python_octopus おつかれさまです！！\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @GodDonut: Python *finira* par être un langage typé https://t.co/USii3gwnWa . Mais forcément, comme pour tout le reste, ça sera mal fait.\n",
      "label: 2 \n",
      "\n",
      "tweet: @mkmnsh_ おつありでございます！！\n",
      "label: 2 \n",
      "\n",
      "tweet: C++ で書かれたサンプルコードを、C# と、それから F# と Python (IronPython) で書き直してみますかな。\n",
      "label: 1 \n",
      "\n",
      "tweet: @python_octopus おつかれさまです！\n",
      "label: 2 \n",
      "\n",
      "tweet: How to protect python class variables from an evil programmer?: How can I protect my… http://t.co/n0AzC6hWWw\n",
      "label: 2 \n",
      "\n",
      "tweet: Object Initialization -- Patterns And Antipatterns - http://t.co/Pi5xu4NMkR\n",
      "label: 2 \n",
      "\n",
      "tweet: 締切まで5時間半。いつもぎりぎりですなぁ。\n",
      "label: 2 \n",
      "\n",
      "tweet: Python! http://t.co/JjdDGlGba1\n",
      "label: 2 \n",
      "\n",
      "tweet: How do I convert this piece of code written in Python 3.4 into Python 2.7 (gives error with end)? http://t.co/Yn5WvjVHZD #Question\n",
      "label: 1 \n",
      "\n",
      "tweet: Dealing with list.index(x) error in Python 3 http://t.co/0jp5moJqwh http://t.co/Ntbf0XWdt2 #Python via @dv_geek\n",
      "label: 1 \n",
      "\n",
      "tweet: Create a Freelancer/Elance type site by seekdesign http://t.co/1haUCxuI2g\n",
      "label: 2 \n",
      "\n",
      "tweet: How to add assumptions in limit in Sympy? http://t.co/um3d45PzDu http://t.co/t3TXOZrjLV #Python via @dv_geek\n",
      "label: 2 \n",
      "\n",
      "tweet: えへへ 合同誌原稿終わった\n",
      "label: 2 \n",
      "\n",
      "tweet: I really want to thank @drchuck and @coursera for the great #python course #PR4E. A good starting point, now looking forward to learn more\n",
      "label: 1 \n",
      "\n",
      "tweet: RT @pythontrending: Bedfellows - Command-line tool for exploring the PAC donor-recipient relationship http://t.co/gZ5gFWEVTb #python\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @yuhiro_274: Django, Python, and Class Variables http://t.co/LnHRC1rQQp\n",
      "label: 1 \n",
      "\n",
      "tweet: \"Doctor, I keep thinking I'm a python. Oh you can't get round me like that, you know.\"\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @pythontrending: eatiht - A tool for extracting article text in html documents. http://t.co/Wu2jxwHpWE #python\n",
      "label: 2 \n",
      "\n",
      "tweet: 24.6 10.2 http://t.co/hYAym4DQUR pyupp added to PyPI\n",
      "label: 1 \n",
      "\n",
      "tweet: #empleo #IT A/P   PYTHON   PHP  Y   JAVA - Madrid http://t.co/2HPny4tseI\n",
      "label: 1 \n",
      "\n",
      "tweet: rt Monty Python's Silly Walk to PHUKET LEARN GOOD ENGLISH -  http://t.co/GiZnKicQMf\n",
      "label: 2 \n",
      "\n",
      "tweet: rt Monty Python's Silly Walk to PHUKET LEARN GOOD ENGLISH -  http://t.co/xH9w7LcUW9\n",
      "label: 2 \n",
      "\n",
      "tweet: rt Monty Python's Silly Walk to PHUKET LEARN GOOD ENGLISH -  http://t.co/5jDQynuWnl\n",
      "label: 2 \n",
      "\n",
      "tweet: Let us always carry with us into each generation the legacy of Monty Python.\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @kinori51: Can't input (č ć š ž đ ) in python 2.7.x console [duplicate] http://t.co/WCev9si6nK\n",
      "label: 1 \n",
      "\n",
      "tweet: ありがとうございます。\n",
      "label: 2 \n",
      "\n",
      "tweet: Python Data Visualization Cookbook http://t.co/W18vDQBzgE 1728 http://t.co/FeGqj442Gy\n",
      "label: 2 \n",
      "\n",
      "tweet: monty python http://t.co/t6g9nDIlJL\n",
      "label: 2 \n",
      "\n",
      "tweet: RT @NYDailyNews: A 15-foot Burmese python was found at a Florida real estate office. http://t.co/ry0yXBZ6Ek http://t.co/1CQVQuZVjj\n",
      "label:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    try:\n",
    "        print(f\"tweet: {tweet_sample[i]['text']}\")\n",
    "        print(f\"label: {label} \\n\")\n",
    "        dataset.append([i, label])\n",
    "    except:\n",
    "        print(f'invalid key: {i} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tweet IDs and labels saved, we can recreate the original\n",
    "dataset. If you are looking to recreate the dataset I used for this chapter, it can be\n",
    "found in the code bundle that comes with this book.\n",
    "\n",
    "Loading the preceding dataset is not difficult but it can take some time. Start a\n",
    "new IPython Notebook and set the dataset, label, and tweet ID filenames as before.\n",
    "I've adjusted the filenames here to ensure that you don't overwrite your previously\n",
    "collected dataset, but feel free to change these if you want. The code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets = [t.lower() for t in tweets[:n_samples]]\n",
    "labels = labels[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_true = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:.1f}% have class 1\".format(np.mean(y_true == 1) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from nltk import word_tokenize\n",
    "\n",
    "class NLTKBOW(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [{word: True for word in word_tokenize(document)}\n",
    "                 for document in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([('bag-of-words', NLTKBOW()),\n",
    "                     ('vectorizer', DictVectorizer()),\n",
    "                     ('naive-bayes', BernoulliNB())\n",
    "                     ])\n",
    "scores = cross_val_score(pipeline, sample_tweets, y_true, cv=10, scoring='f1')\n",
    "print(\"Score: {:.3f}\".format(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
